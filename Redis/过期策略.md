### 过期的Key集合
- 定期删除

redis会将每个设置了过期时间的key放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。

- 惰性删除

在客户端访问这个key的时候，redis对key的过期时间进行检查，如果过期了就立即删除。

注意:定时删除是集中处理，惰性删除是零散处理。

#### 定时扫描策略
Redis 默认每间隔100毫秒进行一次(每秒进行十次)过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。
- 从过期字典中随机20 个key ;
- 删除这20个key中已经过期的key ;
- 如果过期的 key 比率超过1/4，那就重复步骤1 ;

注意: 保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。

#### 从库的过期策略
从库不会进行过期扫描，从库对过期的处理是被动的。主库在key到期时，会在AOF文件里增加一条del指令，同步到所有的从库，从库通过执行这条del指令来删除过期的key。

因为指令同步是异步进行的，所以主库过期的key的del指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在，会导致一些bug。

#### 问题:
设想一个大型的 Redis实例中所有的key在同一时间过期了，会出现怎样的结果?毫无疑问，Redis会持续扫描过期字典(循环多次)，直到过期字典中过期的key变得稀疏，才会停止(循环次数明显下降)。这就会导致线上读写请求出现明显的卡顿现象。导致这种卡顿的另外一种原因是内存管理器需要频繁回收内存页，这也会产生一定的CPU消耗。

也许你会争辩说“扫描不是有25ms的时间上限了么，怎么会导致卡顿呢”﹖这里打个比方，假如有101个客户端同时将请求发过来了，然后前100个请求的执行时间都是25ms，那么第101个指令需要等待多久才能执行?2500ms，这个就是客户端的卡顿时间，是由服务器不间断的小卡顿积少成多导致的。

所以业务开发人员一定要注意过期时间，如果有大批量的key过期，要给过期时间设置一个随机范围，而不能全部在同一时间过期。
```
#在目标过期时间上增加一天的随机时间
redis.expire_at(key, random.randint(86400) + expire_ts)
```
在一些活动系统中，因为活动是一期一会，下一期活动举办时，前面几期的很多数据都可以丢弃了，所以需要给相关的活动数据设置一个过期时间，以减少不必要的Redis 内存占用。如果不加注意，你可能会将过期时间设置为活动结束时间再增加一个常量的冗余时间，如果参与活动的人数太多，就会导致大量的key同时过期。

掌阅服务端在开发过程中就曾出现过多次因为大量key同时过期导致的卡顿报警现象，通过将过期时间随机化总是能很好地解决了这个问题，希望读者们今后能少犯这样的错误。