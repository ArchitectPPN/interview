#### 怎么判断Redis变慢了？
1. 查看响应时间：redis-cli --latency -h host -p port
2. 当前环境下的Redis基线性能

解释：

1）基线性能：一个系统在低压力/无干扰下的基本性能，这个性能只能由当前的软硬件配置决定。

2）redis-cli命令提供了-intrinsic-latency选项，用来检测和统计测试期间内最大延迟， 这个延迟就可以作为Redis的基线性能。测试时长用-intrinsic-latency选项参数来指定。

#### 哪些场景可能导致Redis变慢？
首先, 查看Redis慢日志
```
#命令执行耗时超过5毫秒,记录慢日志
CONFIG SET slowlog-log-slower-than 5000
#只保留最近500条慢日志
CONFIG SET slowlog-max-len 500
```
执行以下命令就可以查询到最近的慢日志
```
127.0.0.1:6379> SLOWLOG get 5
1) 1) (integer) 32693       # 慢日志ID
   2) (integer) 1593763337  # 执行时间戳
   3) (integer) 5299        # 执行耗时(微秒)
   4) 1) "LRANGE"           # 具体执行的命令和参数
      2) "user_list:2000"
      3) "0"
      4) "-1"
2) 1) (integer) 32692
   2) (integer) 1593763337
   3) (integer) 5044
   4) 1) "GET"
      2) "user_info:1000"
```
#### 1.操作BigKey
如果慢日志中发现,并不是复杂度过高的命令导致,而都是SET/DEL这种简单命令出现在慢日志中,那么可能是实例中写入了BigKey.

Redis在写入数据时, 需要为新的数据分配内存, 相对的, 当从Redis中删除数据时, 会释放对应的内存空间.

BigKey操作缓慢原因:
1. key写入的value非常大, 那么Redis在分配内存时就会比较耗时.
2. 删除key时,释放内存也会比较耗时.

扫描Bigkey:
```
redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01
```
扫描示例:
```
$ redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01
 
...
-------- summary -------
 
Sampled 829675 keys in the keyspace!
Total key length in bytes is 10059825 (avg len 12.13)
 
Biggest string found 'key:291880' has 10 bytes
Biggest   list found 'mylist:004' has 40 items
Biggest    set found 'myset:2386' has 38 members
Biggest   hash found 'myhash:3574' has 37 fields
Biggest   zset found 'myzset:2704' has 42 members
 
36313 strings with 363130 bytes (04.38% of keys, avg size 10.00)
787393 lists with 896540 items (94.90% of keys, avg size 1.14)
1994 sets with 40052 members (00.24% of keys, avg size 20.09)
1990 hashs with 39632 fields (00.24% of keys, avg size 19.92)
1985 zsets with 39750 members (00.24% of keys, avg size 20.03)
```

注意:
1. 对线上实例进行bigkey扫描时, redis的OPS会突增, 为了降低扫描过程中对Redis的影响, 最好控制一下扫描频率, 指定-i参数即可, 表示每次扫描后休息时间间隔, 单位秒.
2. 扫描结果中, 对于容器类型(List/Hash/Set/ZSet)的key, 只能扫描出元素最多的key.但一个key的元素多,不一定代表占用内存也多,你还需要根据业务情况, 进一步评估内存占用情况.

bigkey在很多场景下, 依旧会产生性能问题.例如,bigkey在分片集群模式下, 对于数据迁移会有性能影响,以及数据过期/数据淘汰/透明大页.

解决方案:
1. 业务应用尽量避免写入bigkey
2. 如果你使用Redis 4.0以上版本,用unlink代替del, 此命令可以把释放key内存的操作,放到后台线程去执行,从而降低对Redis的影响
3. 如果使用Redis 6.0以上版本,可以开启lazy-free机制(lazyfree-lazy-user-del = yes), 在执行DEL命令时, 释放内存也会放到后台线程中执行

##### bigkey类型

- ##### hash
我们使用时可能会注意到hash的操作为O(1)的,于是使用hash存储了很多的field,但是很容易忽略潜在的一些风险,比如:哈希表的冲突问题和rehash可能带来的操作阻塞.


#### 2. 集中过期
**表现:**

平时在操作redis时, 并没有延迟很大的情况发生, 但在某个时间点突然出现一波延迟时, 其现象表现为: 变慢的时间点很有规律,例如某个整点,或者每隔多久就会发生一波延迟.

Redis的过期数据采用被动过期+主动过期两种策略(这里不在展开);

这个主动过期key的定时任务, 是在Redis主线程中执行的.所以, 如果出现集中过期,redis会一直重复主动扫描过期key的过程,直到过期key的占比小于1/4.如果出现bigkey,这个过程会更加缓慢, 应用程序访问redis变慢.

**注意:**

主动扫描并删除过期key的操作是不会被慢日志记录的, 慢日志记录**只记录一个命令真正操作内存数据的耗时**,Redis主动删除过期key的逻辑,是在命令真正执行前执行的.

**解决方案:**
1. 检查代码逻辑是否存在造成集中过期的潜在风险, 如果存在将集中过期的key增加一个随机过期时间,把集中过期的时间打散, 降低Redis清理过期Key的压力;
2. redis4.0以上版本,开启lazy-free机制,当删除过期key时, 把释放内存操作放到后台线程中执行, 避免阻塞主线程;
3. 监控redis各项运行状态数据监控起来,在Redis上执行info命令拿到当前实例所有的运行数据.重点关注**expired_keys**, 代表整个实例目前累计删除过期key的数量.**这个指标在很短的时间突增**,报警出来,然后与业务应用报慢的时间点进行分析,确认时间是否一致,如果一致,则可以确认是因为集中过期导致Redis响应变慢;

#### 3. 实例内存达到上限
如果你的redis实例设置了内存上限(maxmemory), 那么也可能导致Redis响应变慢.

通常是将Redis来作为缓存使用,设置一个内存上限和数据淘汰策略;当实例内存达到maxmemory后, 你可能发现每次写入新数据操作延迟变大了;

原因在于, 当Redis内存达到maxmemory之后, 每次写入新的数据之前, Redis必须先从实例中剔除一部分,让整个实例的内存维持在maxmemory之下,然后才能写新数据.剔除旧数据的逻辑也是需要消耗时间的, 具体长短取决于配置的淘汰策略.

一般最常使用的是allkeys-lru/volatile-lru淘汰策略,它们的处理逻辑是,每次从实例中随机取出一批key(这个数量可配置),然后淘汰一个最少访问的key,之后把剩下的key暂存到一个池子中,继续随机取一批key,并与之前池子中的key比较,再淘汰一个最少访问的key.以此往复,直到实例内存降到maxmemory之下.

需要注意的是,Redis的淘汰数据的逻辑与删除过期key的一样,**也是在命令真正执行之前执行的**,也就是说它也会增加我们操作Redis的延迟,而且,写OPS越高,延迟也会越明显.

如果此时你的Redis实例中还存储了bigkey,那么在**淘汰删除bigkey释放内存时,也会耗时比较久.**

解决方案:
1. 避免存储bigkey,降低释放内存的耗时
2. 淘汰策略修改为随机淘汰,随机淘汰比LRU要快很多(视业务情况调整)
3. 拆分实例,把淘汰key的压力分摊到多个实例上
4. 如果使用的redis 4.0版本,开启lazy-free机制,把淘汰key释放内存的操作放到后台线程中执行(配置lazyfree-lazy-eviction = yes)

#### 4. fork耗时严重
为了保证Redis数据的安全性,我们可能会开启后台定时RDB和AOF rewrite功能.如果发现**操作Redis延迟变大,都发生在Redis后台RDB和AOF rewrite期间,那你就需要排查,在这期间有可能导致变慢的情况.

当Redis开启了后台RDB和AOF rewrite后,在执行时,他们都需要主进程创建出一个子进程进行数据持久化.

主进程创建子进程,会调用操作系统提供的fork函数.

fork在执行过程中,**主进程需要拷贝自己的内存页给子进程**,如果这个实例很大,那么拷贝的过程也会比较耗时.

而且这个fork过程会消耗大量的CPU资源,在完成fork之前,整个Redis实例会被堵塞住, 无法处理任何客户端请求.

如果此时你的CPU资源本来就很紧张,那么fork的耗时会更长,甚至达到秒级,这会严重影响Redis的性能.

如何确定确实是因为fork耗时严重导致的Redis延迟变大?可以在Redis上执行info命令,查看latest_fork_usec项,单位微秒.
```
# 上一次fork耗时,单位微秒
latest_fork_usec:59477
```
这个时间就是主进程在fork子进程期间,整个实例阻塞无法处理客户端请求的时间.

如果你发现这个耗时很久,就要警惕起来了,这意味在这期间,你的整个Redis实例都处于不可用的状态.

除了数据持久化会生成RDB之外,当主从节点第一次建立数据同步时,主节点也创建子进程生成RDB,然后发给从节点进行一次全量同步,所以,这个过程也会对Redis产生性能影响.

要避免这种情况,可以采用以下方案进行优化:

1. 控制Redis实例的内存,尽量在10G以下,执行fork的耗时与实力大小有关,实例越大,耗时越久.
2. 合理配置数据持久化策略:在slave节点执行RDB备份,推荐在低峰期执行,而对于丢失数据不敏感的业务(例如把Redis当做纯缓存使用), 可以关闭AOF和AOF rewrite.
3. Redis实例不要部署在虚拟机上: fork的耗时也与系统有关,虚拟机比物理机耗时更久
4. 降低主从库全量同步的概率:适当调大repl-backlog-size参数,避免主从全量同步

#### 5. 开启内存大页
除了上面讲到的子进程RDB和AOF rewrite期间,fork耗时导致的延迟变大之外,这里还有一个方面也会导致性能问题,这就是操作系统是否开启了**内存大页机制**.

**内存大页:**应用程序箱操作系统申请内存时,是按**内存页**进行申请的,而常规的内存页大小是**4KB**.

Linux内核从2.6.38开始,支持了**内存大页机制**,该机制允许应用程序以2MB大小单位,向操作系统申请内存.应用程序每次向操作系统申请的内存单位变大了,但这也意味着申请内存的耗时变长.

**对Redis的影响:**

当Redis在执行后台RDB和AOF rewrite时,采用fork子进程的方式来处理.但主进程fork子进程后,此时的**主进程依旧是可以接受写请求**的,而进来的写请求,会采用copy on write(写时复制)的方式操作内存数据.

也就是说,主进程一旦有数据要修改,Redis并不会直接修改现有内存中的数据,而是**先将这块内存数据拷贝出来,再修改这块新内存的数据**,这就是所谓的「写时复制」(可以理解为: 谁需要发生写操作,谁就需要先拷贝,再修改)..

这样的好处就是,父进程有任何写操作,并不会影响子进程的数据持久化(子进程只持久化fork这一瞬间整个实例中的所有数据即可,不关心新的数据变更,因为子进程只需要一份内存快照,然后持久化到磁盘上).

需要注意的是,主进程在拷贝内存数据时,这个阶段就涉及到新内存的申请,如果此时操作系统开启了内存大页,那么在此期间,客户端即便只修改10B的数据,**Redis在申请内存时也会以2MB为单位向操作系统申请,申请内存的耗时变长,进而导致每个写请求的延迟增加,影响Redis性能**.

如果这个写请求操作的是一个BigKey,那么主进程在拷贝这个bigkey内存块时,一次申请的内存会更大,时间也会更久.bigkey在这里又一次影响了性能.

**解决方案**
1. 关闭内存大页.
```
查看Redis机器是否开启了内存大页:

$ cat /sys/kernel/mm/transparent_hugepage/enabled
[always] madvise never
```
如果输出选项是 always，就表示目前开启了内存大页机制，我们需要关掉它：
```
$ echo never > /sys/kernel/mm/transparent_hugepage/enabled
```

操作系统提供的内存大页机制,其优势是,可以在一定程度上降低应用程序申请内存的次数.
但是对于Redis这种性能和延迟极其敏感的数据库来说,我们希望Redis在每次申请内存时,耗时尽量短,所以不建议你在Redis机器上开启这个机制.

#### 6. 开启AOF

上面分析的RDB和AOF rewrite对Redis性能的影响,主要关注点在fork上.

Redis 开启AOF后,工作原理如下:
1. Redis执行写命令后,把这个命令写入到AOF文件内存中(write系统调用)
2. Redis根据配置的AOF刷盘策略,把AOF内存数据刷到磁盘上(fsync系统调用)

为了保证AOF文件数据的安全性,Redis提供了3种刷盘机制:
1. **appendfsync always:** 主线程每次执行写操作后立即刷盘,此方案会占用比较大的磁盘IO资源,但数据安全性最高
2. **appendfsync no:** 主线程每次写操作只写内存就返回,内存数据什么时候刷到磁盘,交由操作系统决定,此方案对性能影响最小,但数据安全性也最低,Redis宕机时丢失的数据取决于操作系统刷盘时机
3. **appendfsync everysec:** 主线程每次写操作只写内存就返回,然后由后台线程每隔1秒执行一次刷盘操作(触发fsync系统调用),此方案对性能影响相对较小,但当Redis宕机时会丢失1秒的数据

上面三个机制对性能的影响:

**appendfsync-always:**

如果你的AOF配置为appendfsync-always,那么Redis每处理一次写操作,都会把这个命令写入到磁盘中才返回,整个过程都是在主线程执行的,这个过程必然会加重Redis写负担.

原因也很简单,操作磁盘要比操作内存慢几百倍,采用这个配置会严重拖慢Redis的性能,因此我不建议你把AOF刷盘方式配置为always.

**appendfsync-no:**
Redis每次写操作只写内存,什么时候把内存中的数据刷到磁盘,交给操作系统决定,此方案对Redis的性能影响最小,但当Redis宕机时,会丢失一部分数据,为了数据的安全性,一般我们也不采取这种配置.
```
如果你的Redis只用作纯缓存,对于数据丢失不敏感,采用配置appendfsync-no就可以.
```

**appendfsync-everysec:**
这个方案的优势在于: Redis主线程写完内存之后就返回,具体的刷盘操作是放到后台线程中执行的,后台线程每隔1秒把内存中的数据刷到磁盘中.这种情况也会存在导致Redis延迟变大的情况发生,甚至会阻塞整个Redis.试想一下这种情况:当Redis后台线程在执行AOF文件刷盘时,如果此时磁盘IO负载很高,那这个后台线程在执行刷盘操作(fsync系统调用)时就会被阻塞住.此时的主线程依旧会接受写请求,紧接着,主线程又需要把数据写到文件内存中(write系统调用),但此时的后台子线程由于磁盘负载过大,导致fsync发生阻塞,迟迟不能返回,那主线程在执行write调用时,也会被阻塞住,直到后台线程fsync执行完成之后,主线程执行write才能返回成功.

**导致磁盘IO负载过大**
1. 子进程正在执行AOF rewrite, 这个过程会占用大量的磁盘IO资源
```
Redis的AOF后台子线程刷盘操作,撞上了子进程AOF rewrite
```
2. 有其他应用程序在执行大量的写文件操作,也会占用磁盘IO

针对情况2的解决方案:
1. 使用Redis配置:
```
# AOF rewrite 期间，AOF 后台子线程不进行刷盘操作
# 相当于在这期间，临时把 appendfsync 设置为了 none
no-appendfsync-on-rewrite yes
```
2. 检查占用磁盘资源的应用程序, 将该应用程序迁移至其他服务器操作, 或者在服务器空闲时间执行, 避免对Redis产生影响
3. 更换更为高效的磁盘, 如SSD固态硬盘, 提高磁盘IO能力, 保证AOF期间有充足的的磁盘资源可以使用

#### 7. 碎片整里
**碎片产生:**
应用程序频繁修改Redis中的数据时,就有可能导致Redis产生内存碎片.这会降低Redis内存使用率, 可以通过执行Info命令,得到当前实例的内存碎片:
```
# Memory
used_memory:5709194824
used_memory_human:5.32G
used_memory_rss:8264855552
used_memory_rss_human:7.70G
...
mem_fragmentation_ratio:1.45
# 计算公式
mem_fragmentation_ratio = used_memory_rss / used_memory
其中used_memory 表示Redis存储数据的内存大小, 儿used_memory_rss表示操作系统实际分配给Redis进程的大小
如果mem_fragmentation_ratio > 1.5,说明内存碎片率已经超过了50%,需要采用一些措施来降低内存碎片了
```
**解决方案**
1. redis 4.0以下版本, 通过重启来解决
2. redis 4.0版本, 提供了自动碎片整里的功能,可以通过配置开启碎片自动整理, 开启内存碎片整理,可能会导致Redis性能下降

Redis的碎片整理工作是在主线程中执行的,当其进行碎片整理时,必然会消耗CPU资源,产生更多的耗时,从而影响到客户端的请求.Redis碎片整理的参数配置如下:
```
# 开启自动内存碎片整理（总开关）
activedefrag yes
 
# 内存使用 100MB 以下，不进行碎片整理
active-defrag-ignore-bytes 100mb
 
# 内存碎片率超过 10%，开始碎片整理
active-defrag-threshold-lower 10
# 内存碎片率超过 100%，尽最大努力碎片整理
active-defrag-threshold-upper 100
 
# 内存碎片整理占用 CPU 资源最小百分比
active-defrag-cycle-min 1
# 内存碎片整理占用 CPU 资源最大百分比
active-defrag-cycle-max 25
 
# 碎片整理期间，对于 List/Set/Hash/ZSet 类型元素一次 Scan 的数量
active-defrag-max-scan-fields 1000
```

#### 8. 网络带宽过载
如果以上产生性能问题的场景,你都规避掉了,而且Redis也稳定运行了很长时间,但在某个时间点之后开始,操作Redis突然开始变慢了,而且一直持续下去,这种情况又是什么原因导致？

此时你需要排查一下Redis机器的网络带宽是否过载,是否存在某个实例把整个机器的网路带宽占满的情况.

网络带宽过载的情况下,服务器在TCP层和网络层就会出现数据包发送延迟/丢包等情况.

Redis的高性能,除了操作内存之外,就在于网络IO了,如果网络IO存在瓶颈,那么也会严重影响Redis的性能.

如果确实出现这种情况,你需要及时确认占满网络带宽Redis实例,如果属于正常的业务访问,那就需要及时扩容或迁移实例了,避免因为这个实例流量过大,影响这个机器的其他实例.

运维层面,你需要对Redis机器的各项指标增加监控,包括网络流量,在网络流量达到一定阈值时提前报警,及时确认和扩容.

























